{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Found 4 resume(s):\n",
      " - resume1.pdf ( .pdf )\n",
      " - resume2.pdf ( .pdf )\n",
      " - resume3.pdf ( .pdf )\n",
      " - resume4.pdf ( .pdf )\n",
      "\n",
      "Resume text extraction complete.\n",
      "\n",
      "--- resume1.pdf ---\n",
      "Aneeba Waseem Backend Developer | Software Engineering Student aneeba.waseem1403@gmail.com +923184328087 aneeba-waseem-63962a25b Aneeba Waseem Lahore, Pakistan PROFILE Enthusiastic Software Engineering student with hands-on experience in .NET and SQL, eager to contribute to real- world backend development. Skilled in building efficient APIs and database solutions, with a strong commitment to writing clean, maintainable code and continuously evolving through practical learning. EDUCATION BS Softw...\n",
      "\n",
      "\n",
      "--- resume2.pdf ---\n",
      "Noor Fatima Software Engineering Student h.noorfatima7@gmail.com +92 323 4753925 Noor Fatima noor_fatima7 Noor Fatima 7_noorfatima Profile I am a passionate Software Engineering student with a strong interest in problem-solving and full-stack development. I have hands-on experience building projects and collaborating in team environments. Actively involved in tech communities, I continuously seek opportunities to learn, innovate, and contribute to meaningful solutions. My ultimate goal is to sta...\n",
      "\n",
      "\n",
      "--- resume3.pdf ---\n",
      "Naushin Saba Khalid Pharmacy assistant ssaba_khalid@yahoo.com +1 (204) 230-7047 Winnipeg, Canada PROFILE My objective is to accomplish a long term career position in a well reputed organization where I can use and replenish my skills and talent through hard work and integrity and learn new skills related to my field PUBLICATIONS Effect of Lycopersicon Esculentum on angiogenesis using Chick Chorioallantoic membrane model. (Under process) Pakistan Journal of Botany EDUCATION M.Phil (Pharmacology &...\n",
      "\n",
      "\n",
      "--- resume4.pdf ---\n",
      "CHARLES MCTURLAND SOFTWARE ENGINEER CONTACT cmcturland@email.com (123) 456-7890 New York, NY LinkedIn EDUCATION B.S. Computer Science University of Pittsburgh September 2008 - April 2012 Pittsburgh, PA SKILLS Python (Django) Javascript (NodeJS ReactJS, jQuery) SQL (MySQL, PostgreSQL, NoSQL) HTML5/CSS AWS Unix, Git WORK EXPERIENCE Software Engineer Embark January 2015 - current / New York, NY Worked with product managers to re-architect a multi-page web app into a single page web-app, boosting ye...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 1: Setup & Load All Resumes =====\n",
    "\n",
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key from .env if exists\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not GOOGLE_API_KEY:\n",
    "    GOOGLE_API_KEY = input(\"Enter your GOOGLE_API_KEY: \").strip()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "\n",
    "# Path to resumes folder\n",
    "resumes_folder = Path(\"../resumes\")  # Adjust relative path from scripts/\n",
    "if not resumes_folder.exists():\n",
    "    raise FileNotFoundError(f\"Resumes folder not found: {resumes_folder}\")\n",
    "\n",
    "# Supported file types\n",
    "supported_ext = [\".pdf\", \".docx\", \".txt\"]\n",
    "\n",
    "# Gather all supported files\n",
    "resume_files = [f for f in resumes_folder.glob(\"*.*\") if f.suffix.lower() in supported_ext]\n",
    "if not resume_files:\n",
    "    raise FileNotFoundError(\"No supported resume files found in the folder.\")\n",
    "\n",
    "print(f\" Found {len(resume_files)} resume(s):\")\n",
    "for f in resume_files:\n",
    "    print(\" -\", f.name, \"(\", f.suffix.lower(), \")\")\n",
    "\n",
    "# Function to extract text from a single file \n",
    "def extract_text(file_path):\n",
    "    text = \"\"\n",
    "    ext = file_path.suffix.lower()\n",
    "    \n",
    "    if ext == \".pdf\":\n",
    "        try:\n",
    "            with fitz.open(file_path) as doc:\n",
    "                for page in doc:\n",
    "                    text += page.get_text(\"text\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read PDF {file_path.name}: {e}\")\n",
    "    elif ext == \".docx\":\n",
    "        try:\n",
    "            from docx import Document\n",
    "            doc = Document(file_path)\n",
    "            text = \"\\n\".join(p.text for p in doc.paragraphs)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read DOCX {file_path.name}: {e}\")\n",
    "    elif ext == \".txt\":\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                text = f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read TXT {file_path.name}: {e}\")\n",
    "    else:\n",
    "        print(f\"Unsupported file type: {file_path.suffix}\")\n",
    "    \n",
    "    # Clean text\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "# Extract text from all resumes \n",
    "resumes_texts = {f.name: extract_text(f) for f in resume_files}\n",
    "print(\"\\nResume text extraction complete.\\n\")\n",
    "for name, text in resumes_texts.items():\n",
    "    print(f\"--- {name} ---\")\n",
    "    preview = text[:500] + (\"...\" if len(text) > 500 else \"\")\n",
    "    print(preview)\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\FYP\\IntelliHire\\INTELLIHIRE.AI\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction result:\n",
      "\n",
      "\"```json\\n{\\n  \\\"name\\\": \\\"CHARLES MCTURLAND\\\",\\n  \\\"contact_info\\\": {\\n    \\\"phone\\\": \\\"(123) 456-7890\\\",\\n    \\\"email\\\": \\\"cmcturland@email.com\\\"\\n  },\\n  \\\"github_link\\\": null,\\n  \\\"linkedin\\\": null,\\n  \\\"qualification\\\": \\\"B.S. Computer Science\\\",\\n  \\\"university\\\": \\\"University of Pittsburgh\\\",\\n  \\\"experience\\\": [\\n    {\\n      \\\"title\\\": \\\"Software Engineer\\\",\\n      \\\"company\\\": \\\"Embark\\\",\\n      \\\"dates\\\": \\\"January 2015 - current\\\",\\n      \\\"location\\\": \\\"New York, NY\\\",\\n      \\\"description\\\": [\\n        \\\"Worked with product managers to re-architect a multi-page web app into a single page web-app, boosting yearly revenue by $1.4M\\\",\\n        \\\"Constructed the logic for a streamlined ad-serving platform that scaled to our 35M users, which improved the page speed by 15% after implementation\\\",\\n        \\\"Tested software for bugs and operating speed, fixing bugs and documenting processes to increase efficiency by 18%\\\",\\n        \\\"Iterated platform for college admissions, collaborating with a group of 4 engineers to create features across the software\\\"\\n      ]\\n    },\\n    {\\n      \\\"title\\\": \\\"Software Engineer\\\",\\n      \\\"company\\\": \\\"MarketSmart\\\",\\n      \\\"dates\\\": \\\"April 2012 - January 2015\\\",\\n      \\\"location\\\": \\\"Washington, DC\\\",\\n      \\\"description\\\": [\\n        \\\"Built RESTful APIs that served data to the JavaScript front-end based on dynamically chosen user inputs that handled over 500,000 concurrent users\\\",\\n        \\\"Built internal tool using NodeJS and Pupeteer.js to automate QA and monitoring of donor-facing web app, which improved CTR by 3%\\\",\\n        \\\"Reviewed code and conducted testing for 3 additional features on donor-facing web app that increased contributions by 12%\\\"\\n      ]\\n    },\\n    {\\n      \\\"title\\\": \\\"Software Engineer Intern\\\",\\n      \\\"company\\\": \\\"Marketing Science Company\\\",\\n      \\\"dates\\\": \\\"April 2011 - March 2012\\\",\\n      \\\"location\\\": \\\"Pittsburgh, PA\\\",\\n      \\\"description\\\": [\\n        \\\"Partnered with a developer to implement RESTful APIs in Django, enabling analytics team to increase reporting speed by 24%\\\",\\n        \\\"Using Selenium I built out a unit testing infrastructure for a client application that reduced the number of bugs reported by the client by 11% month over month\\\"\\n      ]\\n    }\\n  ],\\n  \\\"projects\\\": [\\n    {\\n      \\\"name\\\": \\\"Poker Simulation\\\",\\n      \\\"description\\\": \\\"Built a full-stack web app to allow users to simulate and visualize outcomes of poker hands against opponents of different play styles using open source cards.js on the front-end. Utilized sci-kit learn in Python to simulate possible outcomes under different scenarios that the user chose.\\\"\\n    }\\n  ],\\n  \\\"coursework_keywords\\\": null,\\n  \\\"skills_summary\\\": [\\n    \\\"Python (Django)\\\",\\n    \\\"Javascript (NodeJS ReactJS, jQuery)\\\",\\n    \\\"SQL (MySQL, PostgreSQL, NoSQL)\\\",\\n    \\\"HTML5/CSS\\\",\\n    \\\"AWS\\\",\\n    \\\"Unix\\\",\\n    \\\"Git\\\"\\n  ],\\n  \\\"extracurricular\\\": null\\n}\\n```\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import json\n",
    "\n",
    "# Embedding model\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "# Split resume into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "chunks = text_splitter.split_text(text)\n",
    "\n",
    "# Vector DB (FAISS)\n",
    "vectorstore = FAISS.from_texts(chunks, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": len(chunks)})\n",
    "\n",
    "# LLM model\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.2,\n",
    "    google_api_key=os.environ[\"GOOGLE_API_KEY\"]\n",
    ")\n",
    "\n",
    "# Prompt template \n",
    "prompt_template = \"\"\"\n",
    "You are a precise and structured resume parser designed to extract technical information accurately.\n",
    "From the given resume context, extract the following details:\n",
    "- Full name\n",
    "- Contact information (phone number, email)\n",
    "- GitHub profile link\n",
    "- LinkedIn profile link\n",
    "- Qualification and university\n",
    "- Technical experience\n",
    "- Projects\n",
    "- Coursework\n",
    "- Technical skills and tools\n",
    "- Extracurricular or leadership experience\n",
    "Context:\n",
    "{context}\n",
    "Question:\n",
    "{question}\n",
    "Return ONLY a valid JSON object with these keys:\n",
    "name, contact_info, github_link, linkedin, qualification, university, experience, projects, coursework_keywords, skills_summary, extracurricular.\n",
    "\n",
    "If a field doesnâ€™t exist, set it to null.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# RAG chain\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "\n",
    "# Query the chain\n",
    "query = \"Extract all details from this resume including name, qualification, university, contact info, GitHub, LinkedIn, projects, experience, and technical keywords.\"\n",
    "result = chain.invoke({\"query\": query})\n",
    "\n",
    "import json\n",
    "print(\"Extraction result:\\n\")\n",
    "print(json.dumps(result[\"result\"], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IntelliHire venv",
   "language": "python",
   "name": "intelli_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
